{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intiating selenium Chrome driver\n",
    "driver = webdriver.Chrome(executable_path='C:/Users/Nik/OneDrive/dataScience/DSProjects/ChromeDriver/chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions\n",
    "\n",
    "def getYearMatchURLs(year = 2009):\n",
    "\n",
    "    yearURL = 'https://super.rugby/superrugby/fixtures/archives/' + str(year) + '-super-rugby/'\n",
    "\n",
    "    driver.get(yearURL)\n",
    "\n",
    "    sleep(3)#give time for javascript to load more HTML\n",
    "\n",
    "    #store HTML in a soup\n",
    "    soup = BeautifulSoup(driver.find_element_by_tag_name('html').get_attribute('innerHTML'), 'html.parser')\n",
    "    \n",
    "    #Count how many rounds there are\n",
    "    roundCount = len(soup.findAll(\"a\", {\"href\" : re.compile('#round.*')}))\n",
    "    \n",
    "    #Get URL of first \"Match Page\" of year\n",
    "    driver.find_element_by_xpath(\"//a[@data-toggle='tab' and contains(text(),'Fixtures')]\").click()\n",
    "\n",
    "    sleep(3)\n",
    "\n",
    "    driver.find_element_by_xpath(\"//button[@data-toggle='dropdown']\").click()\n",
    "    #loading last round page loads links for all the year's games\n",
    "    driver.find_element_by_xpath(\"//a[@href='#round\" + str(roundCount) + \"']\").click()\n",
    "\n",
    "    sleep(3)\n",
    "    \n",
    "    allLinks = driver.find_elements_by_xpath(\"//i[@class='fa fa-chevron-right']\")\n",
    "    for i in range(len(allLinks)):\n",
    "        allLinks[i] = allLinks[i].find_element_by_xpath(\"./..\").get_attribute('href')\n",
    "    \n",
    "    return allLinks\n",
    "\n",
    "def getMatchData(matchURL):\n",
    "    \n",
    "    driver.get(matchURL)\n",
    "    \n",
    "    sleep(3)\n",
    "    \n",
    "    soup = BeautifulSoup(driver.find_element_by_tag_name('html').get_attribute('innerHTML'), 'html.parser')\n",
    "    \n",
    "    \n",
    "    matchYear = matchURL[52:56]\n",
    "    matchID = matchURL[-3:]\n",
    "        \n",
    "    try:\n",
    "        matchHeader = soup.find(\"table\", {\"class\" : re.compile('Opta-MatchHeader Opta-MatchHeader-Crested.*')})\n",
    "        \n",
    "    \n",
    "        leftTeam = matchHeader.find(\"td\", {\"class\" : re.compile('Opta-Team-Left Opta-TeamName.*')}).renderContents().strip().decode()\n",
    "        rightTeam = matchHeader.find(\"td\", {\"class\" : re.compile('Opta-Team-Right Opta-TeamName.*')}).renderContents().strip().decode()\n",
    "    \n",
    "        \n",
    "        scores = matchHeader.findAll(\"td\", {\"class\": re.compile('Opta-Score.*')})\n",
    "        leftScore = scores[0].find(\"span\").renderContents().strip().decode()\n",
    "        rightScore = scores[1].find(\"span\").renderContents().strip().decode()\n",
    "\n",
    "        refName = soup.find(\"div\", {\"class\" : \"Opta-Matchdata\"}).find(\"dd\").renderContents().strip().decode()\n",
    "\n",
    "        for tbody in soup('tbody'):\n",
    "            for tr in tbody('tr'):\n",
    "                if tr.text =='Penalties conceded':\n",
    "                    leftPenalties = int(tbody('tr')[1]('td')[0].text)\n",
    "                    rightPenalties = int(tbody('tr')[1]('td')[2].text)\n",
    "    except:\n",
    "        leftTeam = matchURL\n",
    "        rightTeam = matchURL\n",
    "        leftScore = matchURL\n",
    "        rightScore = matchURL\n",
    "        refName = matchURL\n",
    "        leftPenalties = matchURL\n",
    "        rightPenalties = matchURL\n",
    "    \n",
    "    return [matchYear, matchID, leftTeam, leftScore, rightTeam, rightScore, refName, leftPenalties, rightPenalties]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearURLs_dict = {}\n",
    "\n",
    "for year in range(2009, 2020):\n",
    "    yearURLs_dict[year] = getYearMatchURLs(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check we have all URLs\n",
    "for year in yearURLs_dict:\n",
    "    print(len(yearURLs_dict[year]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save URLs as csv just in case\n",
    "#row by row to recreate dict easier\n",
    "#from https://thispointer.com/python-how-to-append-a-new-row-to-an-existing-csv-file/\n",
    "\n",
    "for key in yearURLs_dict.keys():\n",
    "    \n",
    "    with open('yearURLs.csv', 'a', newline='') as file:\n",
    "        # Create a writer object from csv module\n",
    "        csv_writer = csv.writer(file)\n",
    "        # Add contents of list as last row in the csv file\n",
    "        csv_writer.writerow(yearURLs_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recreating dict from the csv file\n",
    "yearURLs_dict = {}\n",
    "\n",
    "for year in range(2009, 2020):\n",
    "    yearURLs_dict[year] = []\n",
    "\n",
    "with open('yearURLs.csv') as file:\n",
    "    for key in yearURLs_dict.keys():\n",
    "        line = file.readline().split(\",\")\n",
    "        line[-1] = line[-1].strip()\n",
    "        yearURLs_dict[key] = line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict ={\n",
    "    'matchYear':[],\n",
    "    'matchID':[],\n",
    "    'leftTeam':[],\n",
    "    'leftScore':[],\n",
    "    'rightTeam':[],    \n",
    "    'rightScore':[],\n",
    "    'refName':[],\n",
    "    'leftPenalties':[],\n",
    "    'rightPenalties':[]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get data from each match page\n",
    "\n",
    "for key in yearURLs_dict.keys():\n",
    "    for URL in yearURLs_dict[key]:\n",
    "        matchStats = getMatchData(URL)\n",
    "        data_dict['matchYear'].append(matchStats[0])\n",
    "        data_dict['matchID'].append(matchStats[1])\n",
    "        data_dict['leftTeam'].append(matchStats[2])\n",
    "        data_dict['rightTeam'].append(matchStats[3])\n",
    "        data_dict['leftScore'].append(matchStats[4])\n",
    "        data_dict['rightScore'].append(matchStats[5])        \n",
    "        data_dict['refName'].append(matchStats[6])\n",
    "        data_dict['leftPenalties'].append(matchStats[7])\n",
    "        data_dict['rightPenalties'].append(matchStats[8])\n",
    "        \n",
    "print(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save df as csv to manually find missing data\n",
    "data_df.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recreate df from updated csv file\n",
    "data_df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct column headers\n",
    "data_df.rename(columns = {'rightTeam' : 'leftScore', 'leftScore' : 'rightTeam'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['winningMargin'] = (data_df['leftScore'] - data_df['rightScore']).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['penaltyDiff(l-r)'] = data_df['leftPenalties'] - data_df['rightPenalties']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get array of unique ref names\n",
    "refName_series = pd.Series(data_df['refName'].unique())\n",
    "#save as csv to manually add refs' countries\n",
    "refName_series.to_csv('refNames.csv', index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create refCountry_dict to get ref's country in data_df\n",
    "with open('refNames.csv', mode='r') as file:\n",
    "    refCountry_dict = {rows[0]:rows[1] for rows in csv.reader(file)}\n",
    "\n",
    "#do the same with team countries\n",
    "with open('teamCountries.csv', mode='r') as file:\n",
    "    teamCountry_dict = {rows[0]:rows[1] for rows in csv.reader(file)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['refCountry'] = data_df['refName'].map(refCountry_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['leftCountry'] = data_df['leftTeam'].map(teamCountry_dict)\n",
    "data_df['rightCountry'] = data_df['rightTeam'].map(teamCountry_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
